{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "asjkhsdhkads\n"
      ],
      "metadata": {
        "id": "N1crlRt1vKRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep='\\t', names=['pseudocode', 'cpp_code', 'workerid', 'probid', 'subid', 'line', 'indent'])\n",
        "    df['pseudocode'] = '<sos> ' + df['pseudocode'] + ' <eos>'\n",
        "    df['cpp_code'] = '<sos> ' + df['cpp_code'] + ' <eos>'\n",
        "    return df[['pseudocode', 'cpp_code']].dropna()\n",
        "\n",
        "train_data = load_data('spoc-train-train.tsv')\n",
        "\n",
        "num_words = 20000\n",
        "max_len = 150\n",
        "\n",
        "pseudocode_tokenizer = Tokenizer(num_words=num_words, filters='', lower=True)\n",
        "pseudocode_tokenizer.fit_on_texts(train_data['pseudocode'])\n",
        "X_train = pseudocode_tokenizer.texts_to_sequences(train_data['pseudocode'])\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
        "\n",
        "cpp_tokenizer = Tokenizer(num_words=num_words, filters='', lower=False)\n",
        "cpp_tokenizer.fit_on_texts(train_data['cpp_code'])\n",
        "y_train = cpp_tokenizer.texts_to_sequences(train_data['cpp_code'])\n",
        "y_train = pad_sequences(y_train, maxlen=max_len, padding='post')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53pB558UvF9l",
        "outputId": "816603df-59cd-489f-a910-9370638b7f57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-64d4544762f7>:10: DtypeWarning: Columns (2,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, sep='\\t', names=['pseudocode', 'cpp_code', 'workerid', 'probid', 'subid', 'line', 'indent'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('pseudocode_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(pseudocode_tokenizer, f)\n",
        "with open('cpp_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(cpp_tokenizer, f)"
      ],
      "metadata": {
        "id": "pRaThbSXvPV0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % num_heads == 0\n",
        "        self.depth = d_model // num_heads\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, q, k, v):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.split_heads(self.wq(q), batch_size)\n",
        "        k = self.split_heads(self.wk(k), batch_size)\n",
        "        v = self.split_heads(self.wv(v), batch_size)\n",
        "        attn_output = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32)))\n",
        "        attn_output = tf.matmul(attn_output, v)\n",
        "        attn_output = tf.transpose(attn_output, perm=[0, 2, 1, 3])\n",
        "        return self.dense(tf.reshape(attn_output, (batch_size, -1, self.d_model)))\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, x):\n",
        "        attn_output = self.attention(x, x, x)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"d_model\": self.d_model, \"num_heads\": self.num_heads, \"dff\": self.dff}\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, x, enc_output):\n",
        "        attn1 = self.attention1(x, x, x)\n",
        "        out1 = self.layernorm1(x + attn1)\n",
        "        attn2 = self.attention2(out1, enc_output, enc_output)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "        ffn_output = self.ffn(out2)\n",
        "        return self.layernorm3(out2 + ffn_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"d_model\": self.d_model, \"num_heads\": self.num_heads, \"dff\": self.dff}\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, dff, max_len):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, input_length=max_len)\n",
        "        self.encoder = TransformerEncoder(d_model, num_heads, dff)\n",
        "        self.decoder = TransformerDecoder(d_model, num_heads, dff)\n",
        "        self.final_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        enc_output = self.encoder(self.embedding(inputs))\n",
        "        dec_output = self.decoder(self.embedding(inputs), enc_output)\n",
        "        return self.final_layer(dec_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"d_model\": self.d_model,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dff\": self.dff,\n",
        "            \"max_len\": self.max_len,\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "LZfkSve6uzyq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_words, d_model=128, num_heads=4, dff=512, max_len=max_len)\n",
        "transformer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "transformer.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Save Transformer Model\n",
        "transformer.save('transformer_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWuYpOMfu9tW",
        "outputId": "cf670cf0-69ab-4ebb-bca3-e074a7515bba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 91ms/step - accuracy: 0.9620 - loss: 0.6204 - val_accuracy: 0.9750 - val_loss: 0.1371\n",
            "Epoch 2/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 90ms/step - accuracy: 0.9777 - loss: 0.1149 - val_accuracy: 0.9760 - val_loss: 0.1275\n",
            "Epoch 3/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 89ms/step - accuracy: 0.9797 - loss: 0.0959 - val_accuracy: 0.9765 - val_loss: 0.1258\n",
            "Epoch 4/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 90ms/step - accuracy: 0.9811 - loss: 0.0853 - val_accuracy: 0.9768 - val_loss: 0.1267\n",
            "Epoch 5/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 90ms/step - accuracy: 0.9820 - loss: 0.0797 - val_accuracy: 0.9769 - val_loss: 0.1273\n",
            "Epoch 6/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 90ms/step - accuracy: 0.9826 - loss: 0.0764 - val_accuracy: 0.9770 - val_loss: 0.1285\n",
            "Epoch 7/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 90ms/step - accuracy: 0.9831 - loss: 0.0740 - val_accuracy: 0.9771 - val_loss: 0.1304\n",
            "Epoch 8/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 89ms/step - accuracy: 0.9836 - loss: 0.0716 - val_accuracy: 0.9771 - val_loss: 0.1307\n",
            "Epoch 9/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 90ms/step - accuracy: 0.9837 - loss: 0.0709 - val_accuracy: 0.9772 - val_loss: 0.1312\n",
            "Epoch 10/10\n",
            "\u001b[1m2558/2558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 89ms/step - accuracy: 0.9840 - loss: 0.0696 - val_accuracy: 0.9770 - val_loss: 0.1327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "with open('pseudocode_tokenizer.pkl', 'rb') as f:\n",
        "    pseudocode_tokenizer = pickle.load(f)\n",
        "with open('cpp_tokenizer.pkl', 'rb') as f:\n",
        "    cpp_tokenizer = pickle.load(f)\n",
        "\n",
        "transformer = tf.keras.models.load_model('transformer_model.keras', compile=False)\n",
        "\n",
        "def generate_cpp_code(pseudocode, max_len=150):\n",
        "    input_seq = pseudocode_tokenizer.texts_to_sequences([\"<sos> \" + pseudocode + \" <eos>\"])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "    pred_seq = transformer.predict(input_seq)\n",
        "    pred_indices = np.argmax(pred_seq, axis=-1)[0]\n",
        "    cpp_tokens = [cpp_tokenizer.index_word.get(idx, '') for idx in pred_indices if idx > 0]\n",
        "\n",
        "    return ' '.join(cpp_tokens).replace('<sos>', '').replace('<eos>', '').strip()\n",
        "\n",
        "pseudocode_example = \"read s\"\n",
        "cpp_output = generate_cpp_code(pseudocode_example)\n",
        "print(\"Generated C++ Code:\\n\", cpp_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEnNdPZ2va_u",
        "outputId": "63c46adc-5ad2-4911-8932-9a65a66a50aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956ms/step\n",
            "Generated C++ Code:\n",
            " cin >> s;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUPJHN8k6amC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}